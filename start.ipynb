{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Flatten, MaxPooling2D, PreprocessingLayer, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Veggie Classification\n",
    "\n",
    "For this assignment you'll need to classify some images of vegetables. \n",
    "\n",
    "## Deliverables\n",
    "\n",
    "Please submit your files into Moodle as follows:\n",
    "<ul>\n",
    "<li> A zipped .h5 model that has been trained. See the notes towards the end of the file. \n",
    "<li> Your .ipynb file. \n",
    "<li> A note (~1 to 2 paragraphs) in the comments of Moodle noting what you did to improve accuracy beyond just making a model. \n",
    "</ul>\n",
    "\n",
    "### Grades\n",
    "\n",
    "<ul>\n",
    "<li> Accuracy - 60%\n",
    "<li> Code - readable and logical - 20%\n",
    "<li> Explainatory note - 20%\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training and Validation Data\n",
    "\n",
    "Please download the zip file from moodle and place it into your folder. If running on Colab you'll need to load it into the workspace. \n",
    "\n",
    "#### Colab and Files\n",
    "\n",
    "You can load files into your Colab workspace via a drag and drop, however this file storage is temporary and will go away when you end your runtime. You can also use your Google drive to store it without having to load it multiple times - there are lots of guides online to setting this up. \n",
    "\n",
    "#### Temporary Files\n",
    "\n",
    "If there are temporary files generated anywhere in the image folders you will need to remove them or you will probably get weird errors. For example, on a Mac (which I'm using to make this), there are temporary files that start with \"._\". If these appear for you, you can clear them via:\n",
    "<ul>\n",
    "<li> Mac: open a terminal at the top level of the image folder and run \"dot_clean -n .\"\n",
    "<li> Windows: open a command prompt at the top level of the image folder and run \"find . -name \"._*\" -exec rm '{}' \\; -print\"\n",
    "</ul>\n",
    "\n",
    "If this doesn't work, or if there are any other temporary files created in your file system you can remove them any other way - e.g. use search to find the files and remove them, sort by filetype and delete, etc... The commands above are just shortcuts. \n",
    "\n",
    "#### File Naming\n",
    "\n",
    "Once things are unzipped ensure that the paths are correct and match your file paths. \n",
    "\n",
    "#### Loading from Google Drive\n",
    "\n",
    "You can also use an adaptation of the code below to load the file from your Google Drive if you're in Colab. You'll get some permission prompts if you haven't done this before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#!cp \"/content/drive/My Drive/Vegetables.zip\" \"Vegetables.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNZIP - Ensure that the filename is correct\n",
    "import zipfile\n",
    "\n",
    "zip_name = \"Vegetables.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 10 classes.\n",
      "Found 4000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate Datasets - you can change this if desired\n",
    "# ENSURE FILE PATHS MATCH CORRECTLY\n",
    "IMAGE_SIZE=(224,224)\n",
    "train_dir='Vegetables/train'\n",
    "val_dir='Vegetables/validation'\n",
    "\n",
    "# Load training data\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size = IMAGE_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare Size Variables - Needed for Compressing\n",
    "batch_size = 64\n",
    "train_samples = 10000\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Data\n",
    "\n",
    "After the file has been unzipped and loaded into datasets, you should see:\n",
    "\n",
    "Found 20000 files belonging to 10 classes.\n",
    "Found 4000 files belonging to 10 classes.\n",
    "\n",
    "The first is the training dataset, the second is the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Modelling Stuff\n",
    "#######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE - HOLD ON FINAL SUBMISSION STUFF\n",
    "## I NEED TO ENSURE THAT THERE'S NO CHANCE OF ANYONE EXCEEDING SIZE LIMITS OF MOODLE\n",
    "\n",
    "### Compress and Save Model\n",
    "\n",
    "For this you have a hard upper limit for model size of 400mb. Why? This is the largest that Moodle can accept, and I do not have any way to work around that. \n",
    "\n",
    "The model will probably need to be pruned to be smaller, then compressed as a zip. In testing this the size can very by a lot, pruning and compressing can get it down to less than 100mb. The size of yours does not matter, as long as it is small enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compression Setup\n",
    "\n",
    "#model = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_model_optimization\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "end_step = np.ceil(1.0 * train_samples / batch_size).astype(np.int32) * epochs\n",
    "print(end_step)\n",
    "\n",
    "new_pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.90,\n",
    "                                                   begin_step=0,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=100)\n",
    "}\n",
    "\n",
    "new_pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, **new_pruning_params)\n",
    "new_pruned_model.summary()\n",
    "\n",
    "new_pruned_model.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs\"\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=logdir, profile_batch=0)\n",
    "]\n",
    "\n",
    "new_pruned_model.fit(train_ds,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks,\n",
    "          validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tfmot.sparsity.keras.strip_pruning(new_pruned_model)\n",
    "final_model.save(\"final.h5\")\n",
    "final_model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ml3950')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
